{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as p\n# data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:17.212831Z","iopub.execute_input":"2025-11-06T05:52:17.213084Z","iopub.status.idle":"2025-11-06T05:52:17.224018Z","shell.execute_reply.started":"2025-11-06T05:52:17.213063Z","shell.execute_reply":"2025-11-06T05:52:17.223428Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:17.224814Z","iopub.execute_input":"2025-11-06T05:52:17.225518Z","iopub.status.idle":"2025-11-06T05:52:17.299111Z","shell.execute_reply.started":"2025-11-06T05:52:17.225490Z","shell.execute_reply":"2025-11-06T05:52:17.298562Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:17.299739Z","iopub.execute_input":"2025-11-06T05:52:17.299917Z","iopub.status.idle":"2025-11-06T05:52:20.806507Z","shell.execute_reply.started":"2025-11-06T05:52:17.299903Z","shell.execute_reply":"2025-11-06T05:52:20.805913Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(train_df.columns)\nprint(train_df.shape,test_df.shape)\nprint(test_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.807137Z","iopub.execute_input":"2025-11-06T05:52:20.807404Z","iopub.status.idle":"2025-11-06T05:52:20.813431Z","shell.execute_reply.started":"2025-11-06T05:52:20.807388Z","shell.execute_reply":"2025-11-06T05:52:20.812813Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n(7613, 5) (3263, 4)\nIndex(['id', 'keyword', 'location', 'text'], dtype='object')\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text=re.sub(r\"https\\S+\",\"\",text)\n    text=re.sub(r\"[^A-Za-z0-9\\s\",\"\",text)\n    return text.lower()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.815332Z","iopub.execute_input":"2025-11-06T05:52:20.815601Z","iopub.status.idle":"2025-11-06T05:52:20.832769Z","shell.execute_reply.started":"2025-11-06T05:52:20.815577Z","shell.execute_reply":"2025-11-06T05:52:20.832033Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from collections import Counter\n\ndef tokenize(text):\n    return text.lower().split()\n\ndef build_vocab(texts, min_freq=2):\n    counter = Counter()\n    for text in texts:\n        counter.update(tokenize(text))\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for word, freq in counter.items():\n        if freq >= min_freq:\n            vocab[word] = len(vocab)\n    return vocab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.833433Z","iopub.execute_input":"2025-11-06T05:52:20.833603Z","iopub.status.idle":"2025-11-06T05:52:20.842039Z","shell.execute_reply.started":"2025-11-06T05:52:20.833588Z","shell.execute_reply":"2025-11-06T05:52:20.841325Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def encode(text, vocab, max_len=32):\n    tokens = tokenize(text)\n    ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n    if len(ids) < max_len:\n        ids += [vocab[\"<pad>\"]] * (max_len - len(ids))\n    else:\n        ids = ids[:max_len]\n    return ids\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.842769Z","iopub.execute_input":"2025-11-06T05:52:20.842990Z","iopub.status.idle":"2025-11-06T05:52:20.850705Z","shell.execute_reply.started":"2025-11-06T05:52:20.842967Z","shell.execute_reply":"2025-11-06T05:52:20.850027Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass TweetDataset(Dataset):\n    def __init__(self, df, vocab):\n        self.texts = df[\"text\"].tolist()\n        self.labels = df[\"target\"].tolist()\n        self.vocab = vocab\n\n    def __getitem__(self, idx):\n        x = torch.tensor(encode(self.texts[idx], self.vocab))\n        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return x, y\n\n    def __len__(self):\n        return len(self.labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.851472Z","iopub.execute_input":"2025-11-06T05:52:20.851678Z","iopub.status.idle":"2025-11-06T05:52:20.859741Z","shell.execute_reply.started":"2025-11-06T05:52:20.851663Z","shell.execute_reply":"2025-11-06T05:52:20.859043Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import torch.nn as nn\n\nclass TweetClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        _, (h_n, _) = self.lstm(x)\n        return torch.sigmoid(self.fc(h_n.squeeze(0)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.860417Z","iopub.execute_input":"2025-11-06T05:52:20.860575Z","iopub.status.idle":"2025-11-06T05:52:20.872444Z","shell.execute_reply.started":"2025-11-06T05:52:20.860563Z","shell.execute_reply":"2025-11-06T05:52:20.871618Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for inputs, labels in dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.873281Z","iopub.execute_input":"2025-11-06T05:52:20.873537Z","iopub.status.idle":"2025-11-06T05:52:20.881633Z","shell.execute_reply.started":"2025-11-06T05:52:20.873505Z","shell.execute_reply":"2025-11-06T05:52:20.880959Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def evaluate_model(model, dataloader, device):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs).squeeze()\n            preds = (outputs > 0.5).float()\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.882261Z","iopub.execute_input":"2025-11-06T05:52:20.882488Z","iopub.status.idle":"2025-11-06T05:52:20.891388Z","shell.execute_reply.started":"2025-11-06T05:52:20.882474Z","shell.execute_reply":"2025-11-06T05:52:20.890726Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\n# Build vocab and dataset\nvocab = build_vocab(train_df[\"text\"])\ndataset = TweetDataset(train_df, vocab)\n\n# Split and load\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=64)\n\n# Initialize model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TweetClassifier(vocab_size=len(vocab)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.BCELoss()\n\n# Train\nfor epoch in range(5):\n    loss = train_model(model, train_loader, optimizer, criterion, device)\n    acc = evaluate_model(model, val_loader, device)\n    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Accuracy={acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:52:20.892072Z","iopub.execute_input":"2025-11-06T05:52:20.892319Z","iopub.status.idle":"2025-11-06T05:52:26.506896Z","shell.execute_reply.started":"2025-11-06T05:52:20.892304Z","shell.execute_reply":"2025-11-06T05:52:26.506321Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss=0.6839, Accuracy=0.5601\nEpoch 2: Loss=0.6775, Accuracy=0.5588\nEpoch 3: Loss=0.6543, Accuracy=0.6362\nEpoch 4: Loss=0.5951, Accuracy=0.6605\nEpoch 5: Loss=0.5219, Accuracy=0.7039\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Load test data\ntest_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\n# Encode test tweets\ntest_encoded = [encode(text, vocab) for text in test_df[\"text\"]]\ntest_tensor = torch.tensor(test_encoded)\ntest_loader = DataLoader(test_tensor, batch_size=64)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:53:18.452838Z","iopub.execute_input":"2025-11-06T05:53:18.453243Z","iopub.status.idle":"2025-11-06T05:53:18.516280Z","shell.execute_reply.started":"2025-11-06T05:53:18.453208Z","shell.execute_reply":"2025-11-06T05:53:18.515687Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model.eval()\npredictions = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        outputs = model(batch).squeeze()\n        preds = (outputs > 0.5).int().cpu().numpy()\n        predictions.extend(preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:53:26.404637Z","iopub.execute_input":"2025-11-06T05:53:26.404895Z","iopub.status.idle":"2025-11-06T05:53:26.490923Z","shell.execute_reply.started":"2025-11-06T05:53:26.404876Z","shell.execute_reply":"2025-11-06T05:53:26.490440Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"target\": predictions\n})\nsubmission.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T05:53:32.924271Z","iopub.execute_input":"2025-11-06T05:53:32.924545Z","iopub.status.idle":"2025-11-06T05:53:32.951947Z","shell.execute_reply.started":"2025-11-06T05:53:32.924524Z","shell.execute_reply":"2025-11-06T05:53:32.951367Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}